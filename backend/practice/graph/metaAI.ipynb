{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_helpfulness(review_text, product_keywords):\n",
    "    # step 1: Preprocessing\n",
    "    review_tokens = word_tokenize(review_text)\n",
    "    review_tokens = [t for t in review_tokens if t.lower(\n",
    "    ) not in nltk.corpus.stopwords.words('english')]\n",
    "\n",
    "    # step 2: Positivity scores\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    positivity_score = sia.polarity_scores(review_text)['compound']\n",
    "\n",
    "    # step 3: Relevance Scores\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    review_vector = tfidf_vectorizer.fit_transform([review_text])\n",
    "    product_vector = tfidf_vectorizer.transform(product_keywords)\n",
    "    relevance_score = cosine_similarity(review_vector, product_vector)[0][0]\n",
    "\n",
    "    # step 4: Informative Scores\n",
    "    informative_score = len(set(review_tokens))\n",
    "\n",
    "    # step 5: length score\n",
    "    length_score = len(review_text)\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    informative_score_normalized = scaler.fit_transform([[informative_score]])[0][0]\n",
    "    length_score_normalized = scaler.fit_transform([[length_score]])[0][0]\n",
    "\n",
    "    # step 6: helpfulness score\n",
    "    helpfulness_score = (positivity_score * 0.4) + (relevance_score * 0.3) + (informative_score * 0.2) + (length_score * 0.1)\n",
    "    print(f\"positivity score: {positivity_score}\")\n",
    "    print(f\"relevance score: {relevance_score}\")\n",
    "    print(f\"informative score: {informative_score}\")\n",
    "    print(f\"length score: {length_score}\")\n",
    "\n",
    "    return helpfulness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivity score: 0.6239\n",
      "relevance score: 0.30151134457776363\n",
      "informative score: 7\n",
      "length score: 65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.240013403373329"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = 'this product is amazing! it exceeded my expectations in every way'\n",
    "product_keywords = [\"product\", \"exceeded expectations\", \"amazing\"]\n",
    "hepfulness_score = calculate_helpfulness(review_text, product_keywords)\n",
    "hepfulness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review body: A powerful, well constructed notebook that provides some useful new features.  So far it has performed well and runs my most demanding applications with no problems.  I particularly like the compactness of the 14.1 inch display and the keyboard has an excellent feel to it.  Things I don't like are the poor speaker sound quality and positioning, the highly reflective display, the Vista user interface, and the lack of a true display mechanical latch.  It would have been nice to have had a CF memory card reader.  This product comes from Amazon with a free upgrade to Windows 7, a nice carry case and a useable optical mouse.\n",
      "review topics: ['14.1 inch display', 'Windows 7', 'carry case', 'optical mouse', 'reflective display', 'vista user interface', 'no CF memory card reader']\n",
      "positivity score: 0.9589\n",
      "relevance score: 0.2077929087308457\n",
      "informative score: 59\n",
      "length score: 627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.94589787261926"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('C:/Hammad Aslam/BS IT (post ADP)/3rd Semester/Capstone Project/Project/backend/datasets/categories/allFiles/computers_laptops.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"review body: {data[2]['reviews'][1]['review_body']}\")\n",
    "print(f\"review topics: {data[2]['reviews'][1]['review_topics']}\")\n",
    "calculate_helpfulness(data[2]['reviews'][1]['review_body'], data[2]['reviews'][1]['review_topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3918800000000005\n",
      "Normalized Helpfulness Score: 0.9349625000000001\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import json\n",
    "\n",
    "with open('C:/Hammad Aslam/BS IT (post ADP)/3rd Semester/Capstone Project/Project/backend/datasets/categories/allFiles/computers_laptops.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Sample review data\n",
    "review = data[4]['reviews'][0]\n",
    "review_rating = float(review['review_rating'])\n",
    "review_text = review['review_body']\n",
    "topics = review['review_topics']\n",
    "helpful_votes = int(review['review_votes'])  # Number of helpful votes provided by other customers\n",
    "\n",
    "# Text analysis using NLTK sentiment analysis\n",
    "def calculate_text_analysis_score(review_text, topics):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sia.polarity_scores(review_text)\n",
    "    # Adjust sentiment score based on relevance of topics\n",
    "    topic_relevance = sum([review_text.lower().count(topic.lower()) for topic in topics])\n",
    "    adjusted_score = sentiment_scores['compound'] + (0.1 * topic_relevance)  # Adjust sentiment score based on topic relevance\n",
    "    return adjusted_score  # Compound score ranges from -1 (negative) to 1 (positive)\n",
    "\n",
    "# Define rating weight, text weight, and helpful votes weight coefficients\n",
    "rating_weight = 0.2\n",
    "text_weight = 0.4\n",
    "helpful_votes_weight = 0.4\n",
    "\n",
    "# Calculate the helpfulness score\n",
    "text_analysis_score = calculate_text_analysis_score(review_text, topics)\n",
    "helpfulness_score = (rating_weight * review_rating) + (text_weight * text_analysis_score) + (helpful_votes_weight * helpful_votes)\n",
    "print(helpfulness_score)\n",
    "\n",
    "# Normalize the helpfulness score to range from 0 to 1\n",
    "min_score = min(review_rating, -1) * rating_weight + min(text_analysis_score, -1) * text_weight + min(helpful_votes, 0) * helpful_votes_weight\n",
    "max_score = max(review_rating, 1) * rating_weight + max(text_analysis_score, 1) * text_weight + max(helpful_votes, 1) * helpful_votes_weight\n",
    "normalized_score = (helpfulness_score - min_score) / (max_score - min_score)\n",
    "\n",
    "print(\"Normalized Helpfulness Score:\", normalized_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
