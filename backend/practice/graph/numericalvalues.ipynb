{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textstat import syllable_count, flesch_reading_ease, automated_readability_index\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('C:/Hammad Aslam/BS IT (post ADP)/3rd Semester/Capstone Project/Project/backend/datasets/categories/allFiles/computers_laptops.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data[0]['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in data:\n",
    "    array = []\n",
    "    for review in product['reviews']:\n",
    "        array.append(review['review_helpfulness'])\n",
    "        \n",
    "for product in data:\n",
    "    for review in product['reviews']:\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        sentiment_scores = sia.polarity_scores(review['review_body'])\n",
    "        review['sentiment'] = \"Positive\" if sentiment_scores['compound'] >= 0.5 else \"Negative\"\n",
    "        # Preprocessing\n",
    "        text = review['review_body']\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [t for t in tokens if t.isalpha() and t.lower() not in nltk.corpus.stopwords.words('english')]\n",
    "        text = ' '.join(tokens)\n",
    "        # Text Metrics Extraction\n",
    "        word_count = len(tokens)\n",
    "        sentence_count = len(nltk.sent_tokenize(text))\n",
    "        # syllable_count = Pyphen().inserted(text).count('-') + 1\n",
    "        character_count = len(text.replace(' ', ''))\n",
    "        fres_score = flesch_reading_ease(text)\n",
    "        ari_score = automated_readability_index(text)\n",
    "        # print(sentiment_scores['compound'])\n",
    "        date_str = review['reviewer_country_date'] if review['reviewer_country_date'] != \"\" else \"January 01, 2010\"\n",
    "        review_timestamp = datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "\n",
    "        # Get the current time (corrected line)\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Calculate the time difference\n",
    "        time_difference = current_time - review_timestamp\n",
    "\n",
    "        # Print the difference in a human-readable format (optional)\n",
    "        # print(f\"The time difference is {time_difference}\")\n",
    "\n",
    "        # Get the difference in specific units (days, seconds, etc.)\n",
    "        days_difference = time_difference.days\n",
    "        decay_factor = 1 - (0.0001 * days_difference)\n",
    "        # print(f\"decay_factor: {decay_factor}\")\n",
    "        rating = float(review['review_rating'])\n",
    "        # helpfulness_score = (rating * 0.2) + (character_count * 0.1) + (word_count * 0.1) + (sentence_count * 0.1) + (100 - fres_score) * 0.2 + (ari_score * 0.2)\n",
    "        # helpfulness_score = ((rating * 0.2) + (character_count * 0.02) + (\n",
    "        #     word_count * 0.13) + (sentence_count * 0.2) + ((100 - fres_score) * 0.1) + (ari_score * 0.1) + (sentiment_scores['compound'] * 0.25)) * decay_factor\n",
    "        if int(review['review_votes']) >= 4:\n",
    "            review['review_helpfulness'] = 'helpful'\n",
    "        else:\n",
    "            review['review_helpfulness'] = 'unhelpful'\n",
    "        # print((review['review_helpfulness'] - min(array)) / (max(array) - min(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Hammad Aslam/BS IT (post ADP)/3rd Semester/Capstone Project/Project/backend/datasets/categories/allFiles/computers_laptops.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
