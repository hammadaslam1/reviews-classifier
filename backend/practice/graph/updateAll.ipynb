{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updating all dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import pymongo\n",
    "import json\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "homePath = \"C:/Hammad Aslam/BS IT (post ADP)/3rd Semester/Capstone Project/Project/backend/datasets/categories/allFiles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating intensity and topics relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_analysis_score(review_text, topics):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sia.polarity_scores(review_text)\n",
    "    # Adjust sentiment score based on relevance of topics\n",
    "    topic_relevance = sum([review_text.lower().count(topic.lower()) for topic in topics])\n",
    "    adjusted_score = sentiment_scores['compound'] + (0.1 * topic_relevance)  # Adjust sentiment score based on topic relevance\n",
    "    return adjusted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updates the data with sentiment scores and helpfulness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setUpdatedValues(data):\n",
    "    \n",
    "    for product in data:\n",
    "        for review in product['reviews']:\n",
    "            text_analysis_score = calculate_text_analysis_score(review['review_body'], review['review_topics'])\n",
    "            # print(text_analysis_score)\n",
    "            helpfulness_score = (0.2 * float(review['review_rating'])) + (0.4 * text_analysis_score) + (0.4 * int(review['review_votes']))\n",
    "            # Normalize the helpfulness score to range from 0 to 1\n",
    "            min_score = min(float(review['review_rating']), -1) * 0.2 + min(text_analysis_score, -1) * 0.4 + min(int(review['review_votes']), 0) * 0.4\n",
    "\n",
    "            max_score = max(float(review['review_rating']), 1) * 0.2 + max(text_analysis_score, 1) * 0.4 + max(int(review['review_votes']), 1) * 0.4\n",
    "\n",
    "            normalized_score = (helpfulness_score - min_score) / (max_score - min_score)\n",
    "            \n",
    "            review['review_helpfulness'] = normalized_score\n",
    "            \n",
    "            sia = SentimentIntensityAnalyzer()\n",
    "            sentiment_scores = sia.polarity_scores(review['review_body'])\n",
    "            review['sentiment'] = \"Positive\" if sentiment_scores['compound'] >= 0.5 else \"Negative\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reads the files and punches the updated data in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFiles(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    newData = setUpdatedValues(data)\n",
    "    with open(file, 'w') as json_file:\n",
    "        json.dump(newData, json_file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accessing each file exactly once in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "52 done\n",
      "1790 done\n",
      "2289 done\n",
      "5517 done\n",
      "6446 done\n",
      "8578 done\n",
      "10539 done\n",
      "12260 done\n",
      "12680 done\n",
      "13396 done\n",
      "14587 done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "def jsonToCsv(attributes, output_file):\n",
    "    count = 0\n",
    "    homePath = 'D:/BS-IT/4th semester/Capstone Project II/opinio/reviews-classifier/backend/datasets/categories/allFiles'\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        # len(data[28]['reviews'])\n",
    "        for filename in os.listdir(homePath):\n",
    "            if filename.endswith(\".json\"):\n",
    "                file = homePath + \"/\" + filename\n",
    "                with open(file, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                # readFiles(file)\n",
    "                print(f\"{count} done\")\n",
    "                for i, product in enumerate(data):\n",
    "                    # for j, review in enumerate(data[28]['reviews']):\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    # Write the header row with selected attributes\n",
    "                    csv_writer.writerow(attributes)\n",
    "                    # Loop through each JSON object (if it's an array)\n",
    "                    if isinstance(product['reviews'], list):\n",
    "                        for item in product['reviews']:\n",
    "                            # Extract values for selected attributes\n",
    "                            row = [item.get(attr) for attr in attributes]\n",
    "                            csv_writer.writerow(row)\n",
    "                            count += 1\n",
    "                    else:\n",
    "                        # Handle single JSON object\n",
    "                        row = [product['reviews'].get(attr) for attr in attributes]\n",
    "                        csv_writer.writerow(row)\n",
    "                        count += 1\n",
    "\n",
    "attributes_to_include = [\"review_body\", \"review_topics\", \"review_votes\", \"sentiment\", \"review_helpfulness\"]\n",
    "output_filename = \"D:/BS-IT/4th semester/Capstone Project II/opinio/reviews-classifier/backend/practice/graph/csv.csv\"\n",
    "\n",
    "jsonToCsv(attributes_to_include, output_filename)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for filename in os.listdir(homePath):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file = homePath + \"/\" + filename\n",
    "        # readFiles(file)\n",
    "        count += 1\n",
    "        print(f\"{count} done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
